{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0517c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Benchmark k·∫øt qu·∫£:\n",
      "Viola-Jones (CPU): 0.0165 ¬± 0.0044 sec\n",
      "YuNet (CPU):       0.0271 ¬± 0.0028 sec\n",
      "EdgeFace (CPU):    0.0084 ¬± 0.0076 sec\n",
      "EdgeFace (GPU):    0.0086 ¬± 0.0089 sec\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o m·∫´u\n",
    "img_path = \"C:/Users/Trung/Downloads/duc.png\"  # ·∫£nh ch·ª©a 1 ho·∫∑c nhi·ªÅu khu√¥n m·∫∑t\n",
    "img = cv2.imread(img_path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# H√†m benchmark th·ªùi gian ch·∫°y\n",
    "def benchmark(func, iterations=20):\n",
    "    times = []\n",
    "    for _ in range(iterations):\n",
    "        start = time.time()\n",
    "        func()\n",
    "        times.append(time.time() - start)\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "# Viola-Jones (Haar Cascade) - ch·ªâ h·ªó tr·ª£ CPU\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "def detect_haar():\n",
    "    _ = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "haar_mean, haar_std = benchmark(detect_haar)\n",
    "\n",
    "# YuNet (ONNX) - h·ªó tr·ª£ CPU v√† GPU\n",
    "\n",
    "def detect_yunet_cpu():\n",
    "    yunet_cpu = cv2.FaceDetectorYN.create(\n",
    "        model=\"D:/Door_Lock_App/models/face_detection_yunet_2023mar.onnx\",\n",
    "        config=\"\",\n",
    "        input_size=(img.shape[1], img.shape[0]),\n",
    "        score_threshold=0.9,\n",
    "        backend_id=cv2.dnn.DNN_BACKEND_DEFAULT,\n",
    "        target_id=cv2.dnn.DNN_TARGET_CPU\n",
    "    )\n",
    "    _ = yunet_cpu.detect(img)\n",
    "\n",
    "def detect_yunet_gpu():\n",
    "    yunet_gpu = cv2.FaceDetectorYN.create(\n",
    "        model=\"D:/Door_Lock_App/models/face_detection_yunet_2023mar.onnx\",\n",
    "        config=\"\",\n",
    "        input_size=(img.shape[1], img.shape[0]),\n",
    "        score_threshold=0.9,\n",
    "        backend_id=cv2.dnn.DNN_BACKEND_CUDA,\n",
    "        target_id=cv2.dnn.DNN_TARGET_CUDA\n",
    "    )\n",
    "    _ = yunet_gpu.detect(img)\n",
    "\n",
    "\n",
    "yunet_cpu_mean, yunet_cpu_std = benchmark(detect_yunet_cpu)\n",
    "# yunet_gpu_mean, yunet_gpu_std = benchmark(detect_yunet_gpu)\n",
    "\n",
    "# EdgeFace (ONNX) nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ ·∫£nh ƒë√£ c·∫Øt\n",
    "edgeface_sess_cpu = ort.InferenceSession(\"D:/Door_Lock_App/models/edgeface_s_gamma_05.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "if 'CUDAExecutionProvider' in ort.get_available_providers():\n",
    "    edgeface_sess_gpu = ort.InferenceSession(\"D:/Door_Lock_App/models/edgeface_s_gamma_05.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
    "else:\n",
    "    edgeface_sess_gpu = None\n",
    "\n",
    "dummy_face = np.random.rand(1, 3, 112, 112).astype(np.float32)  # ·∫£nh khu√¥n m·∫∑t gi·∫£\n",
    "\n",
    "\n",
    "def recognize_edgeface_cpu():\n",
    "    _ = edgeface_sess_cpu.run(None, {\"input.1\": dummy_face})\n",
    "\n",
    "def recognize_edgeface_gpu():\n",
    "    if edgeface_sess_gpu:\n",
    "        _ = edgeface_sess_gpu.run(None, {\"input.1\": dummy_face})\n",
    "\n",
    "edge_cpu_mean, edge_cpu_std = benchmark(recognize_edgeface_cpu)\n",
    "edge_gpu_mean, edge_gpu_std = benchmark(recognize_edgeface_gpu) if edgeface_sess_gpu else (None, None)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(\"‚è±Ô∏è Benchmark k·∫øt qu·∫£:\")\n",
    "print(f\"Viola-Jones (CPU): {haar_mean:.4f} ¬± {haar_std:.4f} sec\")\n",
    "print(f\"YuNet (CPU):       {yunet_cpu_mean:.4f} ¬± {yunet_cpu_std:.4f} sec\")\n",
    "# print(f\"YuNet (GPU):       {yunet_gpu_mean:.4f} ¬± {yunet_gpu_std:.4f} sec\")\n",
    "print(f\"EdgeFace (CPU):    {edge_cpu_mean:.4f} ¬± {edge_cpu_std:.4f} sec\")\n",
    "if edge_gpu_mean:\n",
    "    print(f\"EdgeFace (GPU):    {edge_gpu_mean:.4f} ¬± {edge_gpu_std:.4f} sec\")\n",
    "else:\n",
    "    print(\"EdgeFace (GPU):    ‚ùå GPU kh√¥ng kh·∫£ d·ª•ng\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fcb1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† CPU Inference: 0.0056 ¬± 0.0053 seconds\n",
      "üöÄ GPU Inference: 0.0056 ¬± 0.0057 seconds\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Thay ƒë·ªïi cho ph√π h·ª£p v·ªõi input th·ª±c t·∫ø c·ªßa b·∫°n\n",
    "input_shape = (1, 3, 128, 128)  # V√≠ d·ª• m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t EdgeFace\n",
    "dummy_input = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "def benchmark_onnx(session, input_name, input_tensor, iterations=50):\n",
    "    times = []\n",
    "    for _ in range(iterations):\n",
    "        start = time.time()\n",
    "        session.run(None, {input_name: input_tensor})\n",
    "        times.append(time.time() - start)\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "\n",
    "# T√™n input bi·∫øt tr∆∞·ªõc\n",
    "input_name = \"input\"  # thay b·∫±ng t√™n ƒë√∫ng c·ªßa b·∫°n\n",
    "\n",
    "# Load ONNX model\n",
    "model_path = \"D:/Door_Lock_App/models/AntiSpoofing_cls2_bbox2_sz128_128_best.onnx\"  # thay b·∫±ng ƒë∆∞·ªùng d·∫´n c·ªßa b·∫°n\n",
    "\n",
    "# Session CPU\n",
    "sess_cpu = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# Session GPU (n·∫øu h·ªó tr·ª£)\n",
    "sess_gpu = None\n",
    "if \"CUDAExecutionProvider\" in ort.get_available_providers():\n",
    "    sess_gpu = ort.InferenceSession(model_path, providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "cpu_mean, cpu_std = benchmark_onnx(sess_cpu, input_name, dummy_input)\n",
    "print(f\"üß† CPU Inference: {cpu_mean:.4f} ¬± {cpu_std:.4f} seconds\")\n",
    "\n",
    "if sess_gpu:\n",
    "    gpu_mean, gpu_std = benchmark_onnx(sess_gpu, input_name, dummy_input)\n",
    "    print(f\"üöÄ GPU Inference: {gpu_mean:.4f} ¬± {gpu_std:.4f} seconds\")\n",
    "else:\n",
    "    print(\"‚ùå GPU kh√¥ng kh·∫£ d·ª•ng ho·∫∑c onnxruntime-gpu ch∆∞a ƒë∆∞·ª£c c√†i\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0288f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
